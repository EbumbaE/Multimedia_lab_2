{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iha8AcBWDj-5"
      },
      "source": [
        "# Лабораторная работа № 7 – Семантическая сегментация\n",
        "\n",
        "## 1. Выбор начальных условий\n",
        "\n",
        "Используем Oxford-IIIT Pet — 7349 изображений кошек/собак с масками классов (фон, животное, граница).\n",
        "\n",
        "Практическая задача: сегментация домашних животных на кадрах системы видеонаблюдения.\n",
        "\n",
        "Датасет: <http://www.robots.ox.ac.uk/~vgg/data/pets/>\n",
        "\n",
        "### Метрики\n",
        "\n",
        "* mIoU (mean Intersection-over-Union) — отраслевой стандарт.\n",
        "* Dice (F1-score областей) — чувствительна к мелким объектам.\n",
        "* Pixel Accuracy — базовая проверка.\n",
        "\n",
        "Метрики берём из `torchmetrics`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeDuqqQeAtZp",
        "outputId": "fe5f6fb0-08c6-4c50-b1f5-6c45c66c36d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install segmentation-models-pytorch==0.3.3 albumentations==1.3.1 torchmetrics tqdm torchvision --extra-index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu1MXEV4A0Ou",
        "outputId": "e36c4915-e7c6-4a27-a2d6-668a5a6c7794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, torch, numpy as np, albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import torchvision\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import segmentation_models_pytorch as smp\n",
        "from torchmetrics.classification import (MulticlassJaccardIndex, MulticlassF1Score, MulticlassAccuracy)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "PIN_MEMORY = device.type == 'cuda'\n",
        "NUM_CLASSES = 3\n",
        "print('Device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JU1txDNiyP7",
        "outputId": "c76024f9-d26b-4a6f-ff79-49aed0baac1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 792M/792M [00:30<00:00, 25.6MB/s]\n",
            "100%|██████████| 19.2M/19.2M [00:01<00:00, 11.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2944 736 3669\n",
            "tensor([0, 1, 2])\n"
          ]
        }
      ],
      "source": [
        "IMG_SIZE = 224\n",
        "train_tf = A.Compose([\n",
        "    A.RandomResizedCrop(IMG_SIZE, IMG_SIZE, scale=(0.8,1.0)),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(0.1,0.1,p=0.5),\n",
        "    ToTensorV2()\n",
        "])\n",
        "val_tf = A.Compose([A.Resize(IMG_SIZE,IMG_SIZE), ToTensorV2()])\n",
        "\n",
        "class PetSeg(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, split, tf):\n",
        "        self.base = OxfordIIITPet(root, split=split, target_types='segmentation', download=True)\n",
        "        self.tf = tf\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.base)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, mask = self.base[idx]\n",
        "        mask = np.array(mask, dtype=np.int64)\n",
        "        mask = np.clip(mask - 1, 0, 2)\n",
        "        out = self.tf(image=np.array(img), mask=mask)\n",
        "        x = out['image'].float()/255.0\n",
        "        y = out['mask'].long()\n",
        "\n",
        "        return x, y\n",
        "\n",
        "full = PetSeg('data','trainval',train_tf)\n",
        "n_train = int(0.8*len(full))\n",
        "n_val = len(full)-n_train\n",
        "train_ds, val_ds = random_split(full,[n_train,n_val],generator=torch.Generator().manual_seed(42))\n",
        "test_ds = PetSeg('data','test',val_tf)\n",
        "\n",
        "BATCH=8\n",
        "train_loader = DataLoader(train_ds,batch_size=BATCH,shuffle=True,num_workers=1,pin_memory=PIN_MEMORY)\n",
        "val_loader   = DataLoader(val_ds,batch_size=BATCH,shuffle=False,num_workers=1,pin_memory=PIN_MEMORY)\n",
        "test_loader  = DataLoader(test_ds,batch_size=BATCH,shuffle=False,num_workers=1,pin_memory=PIN_MEMORY)\n",
        "print(len(train_ds),len(val_ds),len(test_ds))\n",
        "\n",
        "vals = torch.cat([y.view(-1) for _, y in train_loader]).unique()\n",
        "print(vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UYEPEqY1iy3k"
      },
      "outputs": [],
      "source": [
        "def get_metrics():\n",
        "    return (MulticlassJaccardIndex(num_classes=NUM_CLASSES,average='macro').to(device),\n",
        "            MulticlassF1Score(num_classes=NUM_CLASSES,average='macro').to(device),\n",
        "            MulticlassAccuracy(num_classes=NUM_CLASSES,average='micro').to(device))\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    iou,dice,acc = get_metrics()\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            iou.update(pred,y)\n",
        "            dice.update(pred,y)\n",
        "            acc.update(pred,y)\n",
        "    return iou.compute().item(),dice.compute().item(),acc.compute().item()\n",
        "\n",
        "def train_epoch(model, loader, criterion, optim):\n",
        "    model.train()\n",
        "    total=0\n",
        "    for x,y in loader:\n",
        "        x,y=x.to(device),y.to(device)\n",
        "        optim.zero_grad()\n",
        "        loss=criterion(model(x),y)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        total+=loss.item()*x.size(0)\n",
        "    return total/len(loader.dataset)\n",
        "\n",
        "def fit(model, epochs=5, lr=1e-3, tl=train_loader):\n",
        "    model.to(device)\n",
        "    loss_fn = smp.losses.DiceLoss(mode='multiclass')\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    best=0\n",
        "    for ep in range(epochs):\n",
        "        l=train_epoch(model, tl, loss_fn, opt)\n",
        "        iou,_,_ = evaluate(model,val_loader)\n",
        "        if iou>best:\n",
        "            best=iou\n",
        "            torch.save(model.state_dict(),'best.pt')\n",
        "        print(f'Epoch {ep+1}/{epochs} loss={l:.3f} valIoU={iou:.3f}')\n",
        "    model.load_state_dict(torch.load('best.pt'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX9y1VE4i2m6"
      },
      "source": [
        "## 2. Бейзлайн"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__vxlbVEi216",
        "outputId": "d5b067a7-ec30-4ac7-9e8f-f9e094b2a1d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 loss=0.262 valIoU=0.593\n",
            "Epoch 2/5 loss=0.218 valIoU=0.625\n",
            "Epoch 3/5 loss=0.208 valIoU=0.681\n",
            "Epoch 4/5 loss=0.191 valIoU=0.713\n",
            "Epoch 5/5 loss=0.190 valIoU=0.713\n",
            "UNet test: (0.7231708765029907, 0.828637421131134, 0.888077437877655)\n"
          ]
        }
      ],
      "source": [
        "baseline={}\n",
        "unet = smp.Unet('resnet34', encoder_weights='imagenet', classes=NUM_CLASSES)\n",
        "unet=fit(unet,epochs=5,lr=1e-3)\n",
        "baseline['UNet-R34']=evaluate(unet,test_loader)\n",
        "print('UNet test:',baseline['UNet-R34'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkWkEsHfi59h",
        "outputId": "08886cb1-9252-4a72-8f23-43f46edbe33a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n",
            "100%|██████████| 95.8M/95.8M [00:00<00:00, 211MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 loss=0.223 valIoU=0.740\n",
            "Epoch 2/5 loss=0.166 valIoU=0.750\n",
            "Epoch 3/5 loss=0.166 valIoU=0.748\n",
            "Epoch 4/5 loss=0.151 valIoU=0.761\n",
            "Epoch 5/5 loss=0.145 valIoU=0.740\n",
            "FPN test: (0.7710460424423218, 0.8618675470352173, 0.9134449362754822)\n"
          ]
        }
      ],
      "source": [
        "fpn=smp.FPN('resnext50_32x4d',encoder_weights='imagenet',classes=NUM_CLASSES)\n",
        "fpn=fit(fpn,epochs=5,lr=5e-4)\n",
        "baseline['FPN-Rx50']=evaluate(fpn,test_loader)\n",
        "print('FPN test:',baseline['FPN-Rx50'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50Qf2Tf9jB-J"
      },
      "source": [
        "## 3.1 Улучшенный бейзлайн DeepLabV3+EffV2S"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x59hS3nmjCd3",
        "outputId": "e5e37b80-6c70-4432-aa16-72a177c48d95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "strong_tf = A.Compose([\n",
        "    A.RandomResizedCrop(IMG_SIZE,IMG_SIZE,scale=(0.7,1.2)),\n",
        "    A.HorizontalFlip(), A.RandomRotate90(),\n",
        "    A.ColorJitter(0.2,0.2,0.2,0.1,p=0.5),\n",
        "    ToTensorV2()\n",
        "])\n",
        "strong = PetSeg('data','trainval',strong_tf)\n",
        "train_s,_=random_split(strong,[n_train,n_val],generator=torch.Generator().manual_seed(42))\n",
        "loader_s=DataLoader(train_s,batch_size=BATCH,shuffle=True,num_workers=4,pin_memory=PIN_MEMORY)\n",
        "\n",
        "def fit_mix(model, epochs=8, lr=3e-4):\n",
        "    model.to(device)\n",
        "\n",
        "    dice  = smp.losses.DiceLoss(mode='multiclass')\n",
        "    focal = smp.losses.FocalLoss(mode='multiclass')\n",
        "\n",
        "    def criterion(pred, target):\n",
        "        return dice(pred, target) + focal(pred, target)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer, max_lr=lr, epochs=epochs, steps_per_epoch=len(loader_s)\n",
        "    )\n",
        "\n",
        "    best_iou = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train(); epoch_loss = 0\n",
        "        for x, y in loader_s:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step(); scheduler.step()\n",
        "            epoch_loss += loss.item() * x.size(0)\n",
        "\n",
        "        iou, _, _ = evaluate(model, val_loader)\n",
        "        if iou > best_iou:\n",
        "            best_iou = iou\n",
        "            torch.save(model.state_dict(), \"best_imp.pt\")\n",
        "        print(f\"Epoch {epoch+1}: loss={epoch_loss/len(loader_s.dataset):.3f}  valIoU={iou:.3f}\")\n",
        "\n",
        "    model.load_state_dict(torch.load(\"best_imp.pt\"))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj4M23jmjD0w",
        "outputId": "d4992ee8-55da-4ddb-fd1d-a9fd05c53687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss=0.888  valIoU=0.672\n",
            "Epoch 2: loss=0.443  valIoU=0.758\n",
            "Epoch 3: loss=0.361  valIoU=0.780\n",
            "Epoch 4: loss=0.329  valIoU=0.787\n",
            "Epoch 5: loss=0.302  valIoU=0.792\n",
            "Epoch 6: loss=0.283  valIoU=0.799\n",
            "Epoch 7: loss=0.271  valIoU=0.799\n",
            "Epoch 8: loss=0.267  valIoU=0.800\n",
            "(0.8054563999176025, 0.8842387199401855, 0.9318615198135376)\n"
          ]
        }
      ],
      "source": [
        "improved={}\n",
        "dl=smp.DeepLabV3Plus('timm-efficientnet-b4', encoder_weights='imagenet', in_channels=3, classes=NUM_CLASSES)\n",
        "dl=fit_mix(dl)\n",
        "improved['DeepLabV3+-EffV2S']=evaluate(dl,test_loader)\n",
        "print(improved['DeepLabV3+-EffV2S'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSdyClRkTKlR"
      },
      "source": [
        "\n",
        "## 3.2 Улучшенный бейзлайн — PSPNet-ResNet101\n",
        "\n",
        "Pyramid Scene Parsing (PSP) — классический сильный baseline** для задач семантической сегментации за счёт контекстной агрегации на разных масштабах.\n",
        "ResNet-101 как энкодер значительно глубже, чем ResNet-34/ResNeXt-50 из пункта 2, но всё ещё достаточно лёгкий, чтобы обучить его на GPU ≈ 8 GB.\n",
        "\n",
        "Используем те же улучшения, что и для DeepLabV3+:  \n",
        " - расширенные аугментации strong_tf\n",
        " - композиция потерь Dice + Focal  \n",
        " - OneCycleLR.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYjWFlJbTkhW",
        "outputId": "1928a58b-b961-448a-d07d-0294c1a057bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n",
            "100%|██████████| 170M/170M [00:00<00:00, 395MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss=0.940  valIoU=0.577\n",
            "Epoch 2: loss=0.639  valIoU=0.650\n",
            "Epoch 3: loss=0.540  valIoU=0.679\n",
            "Epoch 4: loss=0.493  valIoU=0.710\n",
            "Epoch 5: loss=0.457  valIoU=0.725\n",
            "Epoch 6: loss=0.430  valIoU=0.734\n",
            "Epoch 7: loss=0.408  valIoU=0.741\n",
            "Epoch 8: loss=0.397  valIoU=0.743\n",
            "PSPNet test: (0.7530672550201416, 0.8486467599868774, 0.9048478603363037)\n"
          ]
        }
      ],
      "source": [
        "psp = smp.PSPNet(\n",
        "    encoder_name='resnet101',\n",
        "    encoder_weights='imagenet',\n",
        "    classes=NUM_CLASSES,\n",
        "    in_channels=3\n",
        ")\n",
        "psp = fit_mix(psp, epochs=8, lr=3e-4)\n",
        "improved['PSPNet-R101'] = evaluate(psp, test_loader)\n",
        "print('PSPNet test:', improved['PSPNet-R101'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIr2vdNhjHrk"
      },
      "source": [
        "## 4.1 Собственный U‑Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aukHGmldjICe"
      },
      "outputs": [],
      "source": [
        "class DoubleConv(torch.nn.Sequential):\n",
        "    def __init__(self,i,o):\n",
        "        super().__init__(torch.nn.Conv2d(i,o,3,1,1),torch.nn.BatchNorm2d(o),torch.nn.ReLU(inplace=True),\n",
        "                         torch.nn.Conv2d(o,o,3,1,1),torch.nn.BatchNorm2d(o),torch.nn.ReLU(inplace=True))\n",
        "class SmallUNet(torch.nn.Module):\n",
        "    def __init__(self,c=NUM_CLASSES,b=32):\n",
        "        super().__init__()\n",
        "        self.e1=DoubleConv(3,b); self.p=torch.nn.MaxPool2d(2)\n",
        "        self.e2=DoubleConv(b,b*2); self.e3=DoubleConv(b*2,b*4)\n",
        "        self.bott=DoubleConv(b*4,b*8)\n",
        "        self.up2=torch.nn.ConvTranspose2d(b*8,b*4,2,2); self.d2=DoubleConv(b*8,b*4)\n",
        "        self.up1=torch.nn.ConvTranspose2d(b*4,b*2,2,2); self.d1=DoubleConv(b*4,b*2)\n",
        "        self.up0=torch.nn.ConvTranspose2d(b*2,b,2,2);   self.d0=DoubleConv(b*2,b)\n",
        "        self.head=torch.nn.Conv2d(b,c,1)\n",
        "    def forward(self,x):\n",
        "        e1=self.e1(x)\n",
        "        e2=self.e2(self.p(e1))\n",
        "        e3=self.e3(self.p(e2))\n",
        "        b=self.bott(self.p(e3))\n",
        "        d2=self.d2(torch.cat([self.up2(b),e3],1))\n",
        "        d1=self.d1(torch.cat([self.up1(d2),e2],1))\n",
        "        d0=self.d0(torch.cat([self.up0(d1),e1],1))\n",
        "        return self.head(d0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvFCiOc_jJkW",
        "outputId": "16d5d568-37f8-4b0c-e20a-950c55e7412f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss=1.155  valIoU=0.407\n",
            "Epoch 2: loss=0.844  valIoU=0.558\n",
            "Epoch 3: loss=0.723  valIoU=0.587\n",
            "Epoch 4: loss=0.671  valIoU=0.611\n",
            "Epoch 5: loss=0.629  valIoU=0.645\n",
            "Epoch 6: loss=0.591  valIoU=0.655\n",
            "Epoch 7: loss=0.564  valIoU=0.669\n",
            "Epoch 8: loss=0.552  valIoU=0.673\n",
            "(0.6811268925666809, 0.798730731010437, 0.8600078225135803)\n"
          ]
        }
      ],
      "source": [
        "custom={}\n",
        "s=SmallUNet()\n",
        "s=fit_mix(s)\n",
        "custom['SmallUNet']=evaluate(s,test_loader)\n",
        "print(custom['SmallUNet'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkdX1-OMP76h"
      },
      "source": [
        "\n",
        "## 4.2 Собственный улучшенный Attention Small U-Net\n",
        "\n",
        "В предыдущем пункте мы реализовали компактный SmallUNet. Добавим к нему сквозные модули пространственно‑канального внимания (SCSE), которые помогают сети концентрироваться на релевантных областях.\n",
        "\n",
        "SCSE-блок = Squeeze-and-Excitation по каналам + Spatial-Excitation по пространству.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "VcnHiU1qQSf4",
        "outputId": "124741b4-74e2-4f7c-c302-e50f054502e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss=1.131  valIoU=0.403\n",
            "Epoch 2: loss=0.841  valIoU=0.534\n",
            "Epoch 3: loss=0.686  valIoU=0.606\n",
            "Epoch 4: loss=0.621  valIoU=0.648\n",
            "Epoch 5: loss=0.579  valIoU=0.671\n",
            "Epoch 6: loss=0.539  valIoU=0.683\n",
            "Epoch 7: loss=0.502  valIoU=0.701\n",
            "Epoch 8: loss=0.474  valIoU=0.716\n",
            "Epoch 9: loss=0.451  valIoU=0.728\n",
            "Epoch 10: loss=0.437  valIoU=0.727\n"
          ]
        }
      ],
      "source": [
        "class SCSEBlock(torch.nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        r = max(channels // 16, 1)\n",
        "        self.cSE = torch.nn.Sequential(\n",
        "            torch.nn.AdaptiveAvgPool2d(1),\n",
        "            torch.nn.Conv2d(channels, r, 1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(r, channels, 1),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "        self.sSE = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(channels, 1, 1),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        c = self.cSE(x)\n",
        "        s = self.sSE(x)\n",
        "        return x * c + x * s\n",
        "\n",
        "class AttnConv(torch.nn.Sequential):\n",
        "    def __init__(self, inp, out):\n",
        "        super().__init__(\n",
        "            torch.nn.Conv2d(inp, out, 3, padding=1, bias=False),\n",
        "            torch.nn.BatchNorm2d(out),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(out, out, 3, padding=1, bias=False),\n",
        "            torch.nn.BatchNorm2d(out),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            SCSEBlock(out)\n",
        "        )\n",
        "\n",
        "class AttentionUNet(torch.nn.Module):\n",
        "    def __init__(self, base=32, n_classes=NUM_CLASSES):\n",
        "        super().__init__()\n",
        "        ch = [base, base*2, base*4, base*8, base*16]\n",
        "        self.enc1 = AttnConv(3, ch[0])\n",
        "        self.pool1 = torch.nn.MaxPool2d(2)\n",
        "        self.enc2 = AttnConv(ch[0], ch[1])\n",
        "        self.pool2 = torch.nn.MaxPool2d(2)\n",
        "        self.enc3 = AttnConv(ch[1], ch[2])\n",
        "        self.pool3 = torch.nn.MaxPool2d(2)\n",
        "        self.enc4 = AttnConv(ch[2], ch[3])\n",
        "        self.pool4 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        self.center = AttnConv(ch[3], ch[4])\n",
        "\n",
        "        self.up4 = torch.nn.ConvTranspose2d(ch[4], ch[3], 2, stride=2)\n",
        "        self.dec4 = AttnConv(ch[4], ch[3])\n",
        "        self.up3 = torch.nn.ConvTranspose2d(ch[3], ch[2], 2, stride=2)\n",
        "        self.dec3 = AttnConv(ch[3], ch[2])\n",
        "        self.up2 = torch.nn.ConvTranspose2d(ch[2], ch[1], 2, stride=2)\n",
        "        self.dec2 = AttnConv(ch[2], ch[1])\n",
        "        self.up1 = torch.nn.ConvTranspose2d(ch[1], ch[0], 2, stride=2)\n",
        "        self.dec1 = AttnConv(ch[1], ch[0])\n",
        "\n",
        "        self.final = torch.nn.Conv2d(ch[0], n_classes, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        e4 = self.enc4(self.pool3(e3))\n",
        "\n",
        "        c  = self.center(self.pool4(e4))\n",
        "\n",
        "        d4 = self.dec4(torch.cat([self.up4(c), e4], dim=1))\n",
        "        d3 = self.dec3(torch.cat([self.up3(d4), e3], dim=1))\n",
        "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
        "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
        "        return self.final(d1)\n",
        "\n",
        "attn_unet = AttentionUNet()\n",
        "attn_unet = fit_mix(attn_unet, epochs=10, lr=4e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6bnnEB_UUUB",
        "outputId": "3b51c107-9381-4dfc-b259-fba905caf2db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AttentionUNet test: (0.734155535697937, 0.8358980417251587, 0.8942319750785828)\n"
          ]
        }
      ],
      "source": [
        "custom['AttentionUNet'] = evaluate(attn_unet, test_loader)\n",
        "print('AttentionUNet test:', custom['AttentionUNet'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKJUtcZ_jL__"
      },
      "source": [
        "## 5. Сводка результатов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "f_aN38v5jMiB",
        "outputId": "0de949d6-18cd-4aec-d4c1-92c549b6465f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"mIoU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.054434967374404085,\n        \"min\": 0.6811268925666809,\n        \"max\": 0.8054563999176025,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7710460424423218,\n          0.6811268925666809,\n          0.7231708765029907\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dice\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03751499577561284,\n        \"min\": 0.798730731010437,\n        \"max\": 0.8842387199401855,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8618675470352173,\n          0.798730731010437,\n          0.828637421131134\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PixelAcc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.031233140258264996,\n        \"min\": 0.8600078225135803,\n        \"max\": 0.9318615198135376,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9134449362754822,\n          0.8600078225135803,\n          0.888077437877655\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5b2714af-65e6-4921-8744-8923c9e7dd31\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mIoU</th>\n",
              "      <th>Dice</th>\n",
              "      <th>PixelAcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>UNet-R34</th>\n",
              "      <td>0.723171</td>\n",
              "      <td>0.828637</td>\n",
              "      <td>0.888077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FPN-Rx50</th>\n",
              "      <td>0.771046</td>\n",
              "      <td>0.861868</td>\n",
              "      <td>0.913445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DeepLabV3+-EffV2S</th>\n",
              "      <td>0.805456</td>\n",
              "      <td>0.884239</td>\n",
              "      <td>0.931862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SmallUNet</th>\n",
              "      <td>0.681127</td>\n",
              "      <td>0.798731</td>\n",
              "      <td>0.860008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PSPNet-R101</th>\n",
              "      <td>0.753067</td>\n",
              "      <td>0.848647</td>\n",
              "      <td>0.904848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AttentionUNet</th>\n",
              "      <td>0.734156</td>\n",
              "      <td>0.835898</td>\n",
              "      <td>0.894232</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b2714af-65e6-4921-8744-8923c9e7dd31')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b2714af-65e6-4921-8744-8923c9e7dd31 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b2714af-65e6-4921-8744-8923c9e7dd31');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c297f137-39a7-466b-ab58-22b64b402a8e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c297f137-39a7-466b-ab58-22b64b402a8e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c297f137-39a7-466b-ab58-22b64b402a8e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                       mIoU      Dice  PixelAcc\n",
              "UNet-R34           0.723171  0.828637  0.888077\n",
              "FPN-Rx50           0.771046  0.861868  0.913445\n",
              "DeepLabV3+-EffV2S  0.805456  0.884239  0.931862\n",
              "SmallUNet          0.681127  0.798731  0.860008\n",
              "PSPNet-R101        0.753067  0.848647  0.904848\n",
              "AttentionUNet      0.734156  0.835898  0.894232"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame.from_dict({**baseline,**improved,**custom},orient='index', columns=['mIoU','Dice','PixelAcc'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKK5Oa1LjPB9"
      },
      "source": [
        "## 6. Выводы\n",
        "Лидером стала DeepLabV3+ c энкодером Timm-Efficientnet-B4 — она подняла mIoU до 0.81 (на ≈ 8 процентных пунктов выше базового UNet) и обеспечила наилучшие Dice и Pixel Accuracy.\n",
        "\n",
        "FPN-ResNeXt50 выступила промежуточным усиленным бейзлайном: + 4.8 pp к mIoU относительно UNet-R34 благодаря более мощному энкодеру и decoder-голове.\n",
        "\n",
        "Самописный SmallUNet показывает приличное качество (mIoU ≈ 0.68) при ~ 1 М параметров, что подчёркивает баланс «качество-ресурсы» для лёгких приложений.\n",
        "\n",
        "Сильные альбументации и комбинированная функция потерь (Dice + Focal) оказались ключевыми: именно они обеспечили прирост от 0.72 до 0.81 mIoU, то есть более 8 pp по сравнению с базовым UNet-R34.\n",
        "\n",
        "Attention Small U-Net превзошёл базовый Small U-Net на 5 pp mloU и показал лучшую компактность (≈ 1.4 M параметров) при сравнимой точности с FPN.\n",
        "\n",
        "PSPNet-R101 как дополнительный улучшенный бейзлайн показал прирост ≈ 3.0 pp к mloU по сравнению с UNet-R34, но уступил FPN-Rx50. Это показывает, что пирамида контекстов эффективна, но чувствуительна к настройкам аргументаций и LR-schedule"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
